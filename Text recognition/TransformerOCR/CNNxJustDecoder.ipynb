{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "670dNtc0LR0z"
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/text/tutorials/transformer\n",
    "# https://keras.io/examples/nlp/neural_machine_translation_with_transformer\n",
    "# https://keras.io/examples/vision/image_captioning\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "sys.path.append('..')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "APPROACH_NAME = 'TransformerOCR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UL95XLRnDLr0"
   },
   "source": [
    "# Check GPU working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QC47NIx6C8tx",
    "outputId": "4a69b76c-3ea0-46f2-f8cf-be6798d6d6c6"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0': raise SystemError('GPU device not found')\n",
    "print('Found GPU at:', device_name)\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0RvhBn63BXh"
   },
   "source": [
    "# Data input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7sM_I-v3BXi"
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = r'../../Dataset/IHR-NomDB'\n",
    "LABELS_PATH = r'../../Dataset/IHR-NomDB/labels.txt'\n",
    "FONT_PATH = r'../../Dataset/NomNaTong-Regular.ttf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9lAUxB63BXj"
   },
   "source": [
    "## Load and remove records with rare characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYzNVfQU18u7",
    "outputId": "b47a887e-c105-4d03-9eb6-ca3308ba2c98",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from loader import DataImporter\n",
    "dataset = DataImporter(DATASET_DIR, LABELS_PATH, min_length=1).remove_rare_chars(1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ufvmp3v18u7"
   },
   "source": [
    "## Data constants and input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EvxKf_W18u8"
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 432, 48\n",
    "PADDING_CHAR = '[PAD]' \n",
    "START_CHAR = '[START]'\n",
    "END_CHAR = '[END]' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buqQdwSa18u8"
   },
   "outputs": [],
   "source": [
    "from loader import DataHandler\n",
    "data_handler = DataHandler(\n",
    "    dataset, \n",
    "    img_size = (HEIGHT, WIDTH), \n",
    "    padding_char = PADDING_CHAR,\n",
    "    start_char = START_CHAR,\n",
    "    end_char = END_CHAR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bN5vVmTP18u9"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = data_handler.max_length\n",
    "START_TOKEN = data_handler.start_token\n",
    "END_TOKEN = data_handler.end_token\n",
    "VOCAB_SIZE = data_handler.char2num.vocab_size()\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqe2peRS3BXr"
   },
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "S_vABuOD3BXs",
    "outputId": "4286fd14-bde2-4846-a42a-1753da92fa83"
   },
   "outputs": [],
   "source": [
    "from visualizer import visualize_images_labels\n",
    "visualize_images_labels(\n",
    "    dataset.img_paths, \n",
    "    dataset.labels, \n",
    "    figsize = (15, 8),\n",
    "    font_path = FONT_PATH, \n",
    "    text_x = WIDTH + 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQgAf-bd3BX0"
   },
   "source": [
    "# Define model components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yu_6hrxZ3BX0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Dense, GRU, Concatenate, Flatten\n",
    "from layers import custom_cnn, reshape_for_rnn, BahdanauAttention\n",
    "EMBEDDING_DIM = 512\n",
    "UNITS = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGD7dMxt3BX1"
   },
   "source": [
    "## The encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRfgDRNZ3BX2"
   },
   "outputs": [],
   "source": [
    "def Encoder(imagenet_model=None, imagenet_output_layer=None, name='Encoder'):\n",
    "    if imagenet_model: # Use Imagenet model as CNN layers\n",
    "        image_input = imagenet_model.input\n",
    "        imagenet_model.layers[0]._name = 'image'\n",
    "        features = imagenet_model.get_layer(imagenet_output_layer).output\n",
    "    else: \n",
    "        image_input = Input(shape=(HEIGHT, WIDTH, 3), dtype='float32', name='image')\n",
    "        conv_blocks_config = {\n",
    "            'block1': {'num_conv': 1, 'filters':  64, 'pool_size': (2, 2)}, \n",
    "            'block2': {'num_conv': 1, 'filters': 128, 'pool_size': (2, 2)}, \n",
    "            'block3': {'num_conv': 2, 'filters': 256, 'pool_size': (2, 2)}, \n",
    "            'block4': {'num_conv': 2, 'filters': 512, 'pool_size': (2, 2)}, \n",
    "            \n",
    "            # Last Conv blocks with 2x2 kernel but without no padding and pooling layer\n",
    "            'block5': {'num_conv': 2, 'filters': 512, 'pool_size': None}, \n",
    "        }\n",
    "        features = custom_cnn(conv_blocks_config, image_input)\n",
    "\n",
    "    # Adding pixel coordinates to image features\n",
    "    batch_size, h, w, _ = tf.shape(features)\n",
    "    x, y = tf.meshgrid(tf.range(w), tf.range(h))\n",
    "    w_loc = tf.one_hot(x, depth=w)\n",
    "    h_loc = tf.one_hot(y, depth=h)\n",
    "    loc = tf.concat([h_loc, w_loc], axis=2)\n",
    "    loc = tf.tile(tf.expand_dims(loc, 0), multiples=[batch_size, 1, 1, 1])\n",
    "    \n",
    "    # (batch_size, height, width, num_features + coord)\n",
    "    features = tf.concat([features, loc], axis=3) \n",
    "    features = reshape_for_rnn(features, dim_to_keep=1)\n",
    "    return tf.keras.Model(inputs=image_input, outputs=features, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8TI5f473BX5"
   },
   "source": [
    "## The decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rV6xo84A3BX6"
   },
   "outputs": [],
   "source": [
    "def Decoder(enc_features_shape, name='Decoder'):\n",
    "    token_input = Input(shape=(1,), name='new_token')\n",
    "    features_input = Input(shape=enc_features_shape, name='encoder_features')\n",
    "    pre_hidden_input = Input(shape=(UNITS,), name='previous_state')\n",
    "    \n",
    "    # Defining attention as a separate model\n",
    "    attention = BahdanauAttention(UNITS)\n",
    "    context_vector, attention_weights = attention(features_input, pre_hidden_input)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = Concatenate(axis=-1, name='context_and_embedding')([\n",
    "        tf.expand_dims(context_vector, 1), \n",
    "        Embedding(VOCAB_SIZE, EMBEDDING_DIM)(token_input)\n",
    "    ])\n",
    "    \n",
    "    # Passing the concatenated vector to the GRU\n",
    "    rnn_output, state = GRU(\n",
    "        units = UNITS, \n",
    "        return_state = True, \n",
    "        return_sequences = True, \n",
    "        name = 'dec_gru'\n",
    "    )(x, initial_state=pre_hidden_input)\n",
    "\n",
    "    # Generate predictions\n",
    "    x = Flatten()(Dense(UNITS)(rnn_output))\n",
    "    y_pred = Dense(VOCAB_SIZE, name='prediction')(x)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs = [token_input, features_input, pre_hidden_input], \n",
    "        outputs = [y_pred, state, attention_weights],\n",
    "        name = name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiaxCJR118vB"
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_imagenet_model, EncoderDecoderModel\n",
    "imagenet_model, imagenet_output_layer = None, None\n",
    "# # Pick a model from https://keras.io/api/applications\n",
    "# imagenet_model = get_imagenet_model('VGG16', (HEIGHT, WIDTH, 1))\n",
    "# imagenet_output_layer = 'block4_pool'\n",
    "# imagenet_model.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(imagenet_model, imagenet_output_layer)\n",
    "decoder = Decoder(encoder.output_shape[1:])\n",
    "model = EncoderDecoderModel(encoder, decoder, data_handler, dec_rnn_name='dec_gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6IfTtNF18vB",
    "outputId": "80aedcb7-dce2-4d6b-86c9-b55a19d406b4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder.summary(line_length=120)\n",
    "print()\n",
    "decoder.summary(line_length=125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjT21l-13BX-"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJa9IM6wePoK",
    "outputId": "8569e982-5986-48a5-bf69-6de58d77fe2c"
   },
   "outputs": [],
   "source": [
    "train_idxs = list(range(int(dataset.size * 0.8)))\n",
    "valid_idxs = list(range(train_idxs[-1] + 1, dataset.size))\n",
    "print('Number of training samples:', len(train_idxs))\n",
    "print('Number of validate samples:', len(valid_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMOpiKBb18vB"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2022)\n",
    "random.shuffle(train_idxs)\n",
    "random.shuffle(valid_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "375pZk8K18vB"
   },
   "outputs": [],
   "source": [
    "# When run on a small RAM machine, you can set use_cache=False to \n",
    "# not run out of memory but it will slow down the training speed\n",
    "train_tf_dataset = data_handler.prepare_tf_dataset(\n",
    "    train_idxs, BATCH_SIZE, drop_remainder=True\n",
    ")\n",
    "valid_tf_dataset = data_handler.prepare_tf_dataset(\n",
    "    valid_idxs, BATCH_SIZE, drop_remainder=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baKJLLO6PGWV"
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J98bxb_PPEOb"
   },
   "outputs": [],
   "source": [
    "from callbacks import EarlyStoppingWithStuck\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "early_stopping_callback = EarlyStoppingWithStuck(patience=5)\n",
    "\n",
    "# Reduce the learning rate once learning stagnates\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss', \n",
    "    patience = 2, # Reduce if no improvement after 2 epochs\n",
    "    min_lr = 1e-6, # Lower bound on the learning rate \n",
    "    factor = 0.5, # => new_lr = lr * factor\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6sh1CdC18vB"
   },
   "source": [
    "## Train the IHR-NomDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HGg9k1t3BX-"
   },
   "outputs": [],
   "source": [
    "from losses import MaskedLoss\n",
    "from metrics import SequenceAccuracy, CharacterAccuracy, LevenshteinDistance\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "LEARNING_RATE = 2e-4\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPVb3axr18vC"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(LEARNING_RATE), \n",
    "    loss = MaskedLoss(), \n",
    "    metrics = [\n",
    "        SequenceAccuracy(),\n",
    "        CharacterAccuracy(),\n",
    "        LevenshteinDistance(normalize=True, name='lev_distance')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CiWc6i5B3BYB",
    "outputId": "79cc561c-f6ec-42b2-b549-3f5a3713e4d0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_tf_dataset,\n",
    "    validation_data = valid_tf_dataset,\n",
    "    epochs = EPOCHS,\n",
    "    callbacks = [reduce_lr_callback, early_stopping_callback],\n",
    "    verbose = 1\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU-5S6vo18vC"
   },
   "source": [
    "## Save the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtA0QVnz18vC"
   },
   "outputs": [],
   "source": [
    "best_epoch = early_stopping_callback.best_epoch\n",
    "print(f'- Loss on validation\\t: {history[\"val_loss\"][best_epoch]}')\n",
    "print(f'- Sequence accuracy\\t: {history[\"val_seq_acc\"][best_epoch]}')\n",
    "print(f'- Character accuracy\\t: {history[\"val_char_acc\"][best_epoch]}')\n",
    "print(f'- Levenshtein distance\\t: {history[\"val_lev_distance\"][best_epoch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5MgFd3a18vC"
   },
   "outputs": [],
   "source": [
    "from visualizer import plot_training_results\n",
    "plot_training_results(history, f'{APPROACH_NAME}.png')\n",
    "model.encoder.save_weights(f'{APPROACH_NAME}_encoder.h5')\n",
    "model.decoder.save_weights(f'{APPROACH_NAME}_decoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSAljxKY18vC"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CE7jIqCl18vC"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(imagenet_model, imagenet_output_layer)\n",
    "decoder = Decoder(encoder.output_shape[1:])\n",
    "encoder.load_weights(f'{APPROACH_NAME}_encoder.h5')\n",
    "decoder.load_weights(f'{APPROACH_NAME}_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRddbIUi18vD"
   },
   "outputs": [],
   "source": [
    "reset_model = EncoderDecoderModel(encoder, decoder, data_handler, dec_rnn_name='dec_gru')\n",
    "reset_model.compile(\n",
    "    optimizer = Adam(LEARNING_RATE), \n",
    "    loss = MaskedLoss(), \n",
    "    metrics = [\n",
    "        SequenceAccuracy(),\n",
    "        CharacterAccuracy(),\n",
    "        LevenshteinDistance(normalize=True, name='lev_distance')\n",
    "    ]\n",
    ")\n",
    "reset_model.evaluate(valid_tf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1UkLQIT18vD"
   },
   "source": [
    "## On test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzfgGHNf18vD",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_results = []\n",
    "for idx, (batch_images, batch_tokens) in enumerate(valid_tf_dataset.take(2)):\n",
    "    idxs_in_batch = valid_idxs[idx * BATCH_SIZE: (idx + 1) * BATCH_SIZE]\n",
    "    labels = data_handler.tokens2texts(batch_tokens)\n",
    "    pred_tokens, attentions = reset_model.predict(batch_images, return_attention=True)\n",
    "    pred_labels = data_handler.tokens2texts(pred_tokens)\n",
    "    \n",
    "    batch_results.append({'true': labels, 'pred': pred_labels, 'attentions': attentions})\n",
    "    visualize_images_labels(\n",
    "        img_paths = dataset.img_paths[idxs_in_batch], \n",
    "        labels = labels, \n",
    "        pred_labels = pred_labels,\n",
    "        figsize = (14, 20),\n",
    "        subplot_size = (4, 8),\n",
    "        legend_loc = (3.8, 4.28),\n",
    "        annotate_loc = (4, 1.8),\n",
    "        font_path = FONT_PATH, \n",
    "        text_x = WIDTH + 5 # Position of actual label to plot\n",
    "    )\n",
    "    print(\n",
    "        f'Batch {idx + 1:02d}:\\n'\n",
    "        f'- True: {dict(enumerate(labels, start=1))}\\n'\n",
    "        f'- Pred: {dict(enumerate(pred_labels, start=1))}\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLRmJs-N18vD"
   },
   "source": [
    "## On random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TumY4TEf18vD"
   },
   "outputs": [],
   "source": [
    "random_path = '../囷𦝄苔惮󰞺𧍋𦬑囊.jpg'\n",
    "random_label = '囷𦝄苔惮󰞺𧍋𦬑囊'\n",
    "random_image = data_handler.process_image(random_path)\n",
    "pred_tokens = reset_model.predict(tf.expand_dims(random_image, axis=0))\n",
    "pred_labels = data_handler.tokens2texts(pred_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNVbsf5mRycj"
   },
   "outputs": [],
   "source": [
    "visualize_images_labels(\n",
    "    img_paths = [random_path], \n",
    "    labels = [random_label], \n",
    "    pred_labels = pred_labels,\n",
    "    figsize = (5, 4),\n",
    "    subplot_size = (1, 1), \n",
    "    font_path = FONT_PATH, \n",
    "    text_x = 40 # Position to plot actual label\n",
    ")\n",
    "print('Predicted text:', ''.join(pred_labels))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Injection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
